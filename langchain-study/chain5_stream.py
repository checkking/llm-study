import os
from langchain_core.messages import AIMessage, HumanMessage, SystemMessage
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain.chat_models import init_chat_model
from langchain_core.output_parsers import StrOutputParser

# ä½¿ç”¨ ç¡…åŸºæµåŠ¨ æ¨¡å‹
model = init_chat_model(
    model="doubao-1-5-pro-32k-250115",
    model_provider="openai",
    base_url="https://ark.cn-beijing.volces.com/api/v3",
    api_key=os.environ.get("ARK_OPENAI_API_KEY"),
)

parser = StrOutputParser()

prompt = ChatPromptTemplate.from_messages([
    SystemMessage(content="ä½ å«å°æ™ºï¼Œæ˜¯äººå·¥æ™ºèƒ½ä¸“å®¶ã€‚"),
    MessagesPlaceholder(variable_name="messages"),
])

chain = prompt | model | parser

messages_list = []  # åˆå§‹åŒ–å†å²
print("ğŸ”¹ è¾“å…¥ exit ç»“æŸå¯¹è¯")
while True:
    user_query = input("ä½ ï¼š")
    if user_query.lower() in {"exit", "quit"}:
        break

    # 1) è¿½åŠ ç”¨æˆ·æ¶ˆæ¯
    messages_list.append(HumanMessage(content=user_query))

    # 2) è°ƒç”¨æ¨¡å‹
    assistant_reply = ''
    print("å°æ™ºï¼š", end=' ')
    for chunk in chain.stream({"messages": messages_list}):
        assistant_reply+=chunk
        print(chunk, end="", flush=True)
    print()

    # 3) è¿½åŠ  AI å›å¤
    messages_list.append(AIMessage(content=assistant_reply))

    # 4) ä»…ä¿ç•™æœ€è¿‘ 50 æ¡
    messages_list = messages_list[-50:]
